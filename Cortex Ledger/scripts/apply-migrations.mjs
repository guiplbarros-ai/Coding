#!/usr/bin/env node

/**
 * Script para aplicar migrations do Supabase
 * Uso: node scripts/apply-migrations.mjs
 */

import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import dotenv from 'dotenv';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const rootDir = join(__dirname, '..');

// Carregar vari√°veis de ambiente
dotenv.config({ path: join(rootDir, '.env') });

const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!SUPABASE_URL || !SERVICE_ROLE_KEY) {
  console.error('‚ùå Erro: SUPABASE_URL ou SERVICE_ROLE_KEY n√£o configurados no .env');
  process.exit(1);
}

// Criar cliente Supabase com service role
const supabase = createClient(SUPABASE_URL, SERVICE_ROLE_KEY, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
});

async function executeSQLFile(filePath, description) {
  console.log(`\nüìù ${description}...`);
  console.log(`   Arquivo: ${filePath}`);

  try {
    const sql = readFileSync(filePath, 'utf-8');
    const lines = sql.split('\n').length;
    console.log(`   Linhas: ${lines}`);

    // Nota: A API do Supabase n√£o permite executar SQL diretamente via client
    // Precisamos usar a API REST do PostgREST ou a Management API

    // Para executar SQL arbitr√°rio, usamos o endpoint RPC ou a Management API
    // Como alternativa, mostramos o conte√∫do para execu√ß√£o manual

    console.log('\n‚ö†Ô∏è  Execu√ß√£o direta via API n√£o suportada.');
    console.log('   Por favor, execute manualmente no Supabase Studio:');
    console.log(`   \n   1. Acesse: ${SUPABASE_URL.replace('https://', 'https://supabase.com/dashboard/project/')}/sql/new`);
    console.log('   2. Cole o conte√∫do do arquivo SQL');
    console.log('   3. Clique em "Run"');
    console.log(`\n   Arquivo SQL:\n   ${filePath}\n`);

    return { success: false, manual: true };
  } catch (error) {
    console.error(`‚ùå Erro ao ler arquivo: ${error.message}`);
    return { success: false, error: error.message };
  }
}

async function verifyConnection() {
  console.log('üîç Verificando conex√£o com Supabase...');
  console.log(`   URL: ${SUPABASE_URL}`);

  try {
    // Tentar uma query simples para verificar conex√£o
    const { data, error } = await supabase
      .from('_realtime')
      .select('*')
      .limit(1);

    if (error && !error.message.includes('does not exist')) {
      console.log('‚úÖ Conex√£o estabelecida!');
      return true;
    }

    // Se a tabela n√£o existe, ainda assim estamos conectados
    console.log('‚úÖ Conex√£o estabelecida!');
    return true;
  } catch (error) {
    console.error(`‚ùå Erro de conex√£o: ${error.message}`);
    return false;
  }
}

async function checkExistingTables() {
  console.log('\nüîç Verificando tabelas existentes...');

  try {
    // Tentar query em uma tabela que seria criada pela migration
    const { data, error } = await supabase
      .from('instituicao')
      .select('id')
      .limit(1);

    if (!error) {
      console.log('‚ö†Ô∏è  Tabelas j√° existem! Migration pode j√° ter sido aplicada.');
      return true;
    }

    console.log('‚úÖ Tabelas n√£o encontradas (migration ainda n√£o aplicada)');
    return false;
  } catch (error) {
    console.log('‚úÖ Tabelas n√£o encontradas (migration ainda n√£o aplicada)');
    return false;
  }
}

async function main() {
  console.log('üöÄ Cortex Ledger - Apply Migrations Script');
  console.log('==========================================\n');

  // Verificar conex√£o
  const connected = await verifyConnection();
  if (!connected) {
    console.error('\n‚ùå N√£o foi poss√≠vel conectar ao Supabase. Verifique as credenciais.');
    process.exit(1);
  }

  // Verificar se migrations j√° foram aplicadas
  const tablesExist = await checkExistingTables();
  if (tablesExist) {
    console.log('\n‚ö†Ô∏è  AVISO: Migrations podem j√° ter sido aplicadas.');
    console.log('   Se continuar, pode haver erros de "already exists".\n');
  }

  // Paths dos arquivos SQL
  const migrationFile = join(rootDir, 'supabase/migrations/20251026T000000_init.sql');
  const seedFile = join(rootDir, 'supabase/seed.sql');

  console.log('\nüìã Plano de Execu√ß√£o:');
  console.log('   1. Migration (schema + RLS + triggers)');
  console.log('   2. Seed (dados de teste)');

  // Executar migration
  const migrationResult = await executeSQLFile(migrationFile, 'Aplicando migration');

  if (migrationResult.manual) {
    console.log('\nüìå INSTRU√á√ïES DE EXECU√á√ÉO MANUAL:');
    console.log('\n1Ô∏è‚É£  MIGRATION (Schema + RLS + Triggers):');
    console.log(`   cat "${migrationFile}" | pbcopy`);
    console.log(`   Abra: ${SUPABASE_URL.replace('https://', 'https://supabase.com/dashboard/project/')}/sql/new`);
    console.log('   Cole o SQL copiado e execute\n');

    console.log('2Ô∏è‚É£  SEED (Dados de teste):');
    console.log(`   cat "${seedFile}" | pbcopy`);
    console.log(`   Abra: ${SUPABASE_URL.replace('https://', 'https://supabase.com/dashboard/project/')}/sql/new`);
    console.log('   Cole o SQL copiado e execute\n');

    console.log('\nüí° ALTERNATIVA - Executar via psql:');
    console.log('   1. Obtenha o database password no Supabase Dashboard');
    console.log('   2. Execute:');
    console.log(`      export PGPASSWORD="sua_senha_aqui"`);
    console.log(`      psql "postgresql://postgres.xborrshstfcvzrxyqyor@aws-0-us-east-1.pooler.supabase.com:6543/postgres" -f "${migrationFile}"`);
    console.log(`      psql "postgresql://postgres.xborrshstfcvzrxyqyor@aws-0-us-east-1.pooler.supabase.com:6543/postgres" -f "${seedFile}"`);
  }

  console.log('\n‚úÖ Script conclu√≠do.');
  console.log('   As migrations precisam ser aplicadas manualmente via Supabase Studio.');
  console.log('   Siga as instru√ß√µes acima.\n');
}

main().catch(console.error);
